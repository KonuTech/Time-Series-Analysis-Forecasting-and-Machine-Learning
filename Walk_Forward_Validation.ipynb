{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Walk-Forward Validation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOLh5uFVXOp8bmXKWEg0b8u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KonuTech/Time-Series-Analysis-Forecasting-and-Machine-Learning/blob/main/Walk_Forward_Validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubzALEhitYo9",
        "outputId": "37eb27fa-186f-49bd-8337-7f64af112b6b"
      },
      "source": [
        "!wget -nc https://lazyprogrammer.me/course_files/airline_passengers.csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-20 18:37:01--  https://lazyprogrammer.me/course_files/airline_passengers.csv\n",
            "Resolving lazyprogrammer.me (lazyprogrammer.me)... 172.67.213.166, 104.21.23.210, 2606:4700:3030::ac43:d5a6, ...\n",
            "Connecting to lazyprogrammer.me (lazyprogrammer.me)|172.67.213.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2036 (2.0K) [text/csv]\n",
            "Saving to: ‘airline_passengers.csv’\n",
            "\n",
            "airline_passengers. 100%[===================>]   1.99K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-06-20 18:37:01 (42.2 MB/s) - ‘airline_passengers.csv’ saved [2036/2036]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWxzjrXath3z",
        "outputId": "b8db5abf-9615-43ef-ec0a-415703e78689"
      },
      "source": [
        "!pip install -U statsmodels"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting statsmodels\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/69/8eef30a6237c54f3c0b524140e2975f4b1eea3489b45eb3339574fc8acee/statsmodels-0.12.2-cp37-cp37m-manylinux1_x86_64.whl (9.5MB)\n",
            "\u001b[K     |████████████████████████████████| 9.5MB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from statsmodels) (0.5.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=1.1 in /usr/local/lib/python3.7/dist-packages (from statsmodels) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from statsmodels) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: pandas>=0.21 in /usr/local/lib/python3.7/dist-packages (from statsmodels) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5->statsmodels) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21->statsmodels) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21->statsmodels) (2018.9)\n",
            "Installing collected packages: statsmodels\n",
            "  Found existing installation: statsmodels 0.10.2\n",
            "    Uninstalling statsmodels-0.10.2:\n",
            "      Successfully uninstalled statsmodels-0.10.2\n",
            "Successfully installed statsmodels-0.12.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry84iqlqtjqG"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import itertools\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLaIjjIrtwp2"
      },
      "source": [
        "df = pd.read_csv('airline_passengers.csv', index_col='Month', parse_dates=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpnMGNY0t7Sg"
      },
      "source": [
        "df.index.freq = 'MS'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jnXje_8uElB",
        "outputId": "174fc959-88d4-432e-f8a4-5937e3691482"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(144, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5us0suvuuFoZ"
      },
      "source": [
        "# Asssume the forecast horizon we care about is 12\n",
        "# Validate over 10 steps\n",
        "h = 12\n",
        "steps = 10\n",
        "Ntest = len(df) - h - steps + 1"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFrfM1btuMFj"
      },
      "source": [
        "# Configuration hyperparametrs to try\n",
        "trend_type_list = ['add', 'mul']\n",
        "seasonal_type_list = ['add', 'mul']\n",
        "damped_trend_list = [True, False]\n",
        "init_method_list = ['estimated', 'heuristic', 'legacy-heuristic']\n",
        "use_boxcox_list = [True, False, 0]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ypn6rftqu59a"
      },
      "source": [
        "# Note: statsmodels documentation states that 'log' is an acceptable input for use_boxcox. This is false."
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utm-Iby3vDxj"
      },
      "source": [
        "def walkforward(\n",
        "    trend_type,\n",
        "    seasonal_type,\n",
        "    damped_trend,\n",
        "    init_method,\n",
        "    use_boxcox,\n",
        "    debug=False\n",
        "    ):\n",
        "\n",
        "    # store errors\n",
        "    errors = []\n",
        "    seen_last = False\n",
        "    steps_completed = 0\n",
        "\n",
        "    for end_of_train in range(Ntest, len(df) - h + 1):\n",
        "      # We don't have to manually \"add\" the data to our dataset\n",
        "      # Just index it at the right points - this is a \"view\" not a \"copy\"\n",
        "      # So it doesn't take up any extra space or computation\n",
        "      train = df.iloc[:end_of_train]\n",
        "      test = df.iloc[end_of_train:end_of_train + h]\n",
        "\n",
        "      if test.index[-1] == df.index[-1]:\n",
        "        seen_last = True\n",
        "      \n",
        "      steps_completed += 1\n",
        "\n",
        "      hw = ExponentialSmoothing(\n",
        "          train['Passengers'],\n",
        "          initialization_method=init_method,\n",
        "          trend=trend_type,\n",
        "          damped_trend=damped_trend,\n",
        "          seasonal=seasonal_type,\n",
        "          seasonal_periods=12,\n",
        "          use_boxcox=use_boxcox)\n",
        "      res_hw = hw.fit()\n",
        "\n",
        "      # compute error for the forecast horizon\n",
        "      fcast = res_hw.forecast(h)\n",
        "      error = mean_squared_error(test['Passengers'], fcast)\n",
        "      errors.append(error)\n",
        "\n",
        "      if debug:\n",
        "        print(\"seen_last:\", seen_last)\n",
        "        print(\"steps_completed:\", steps_completed)\n",
        "\n",
        "      return np.mean(errors)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EkNOeEpyvqp",
        "outputId": "a1d44bfe-e616-4d2d-e4b7-6f107502b4fb"
      },
      "source": [
        "# test our function\n",
        "walkforward('add', 'add', False, 'legacy-heuristic', 0, debug=True)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "seen_last: False\n",
            "steps_completed: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4480.04257518788"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyKFX-L0zQLE",
        "outputId": "636f5640-9b1a-4922-c5e7-f73fd030269f"
      },
      "source": [
        "# Iterate through all possible options (i.e. grif search)\n",
        "tuple_of_option_lists = (\n",
        "    trend_type_list,\n",
        "    seasonal_type_list,\n",
        "    damped_trens_list,\n",
        "    init_method_list,\n",
        "    use_boxcox_list\n",
        ")\n",
        "\n",
        "for x in itertools.product(*tuple_of_option_lists):\n",
        "  print(x)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('add', 'add', True, 'estimated', True)\n",
            "('add', 'add', True, 'estimated', False)\n",
            "('add', 'add', True, 'estimated', 0)\n",
            "('add', 'add', True, 'heuristic', True)\n",
            "('add', 'add', True, 'heuristic', False)\n",
            "('add', 'add', True, 'heuristic', 0)\n",
            "('add', 'add', True, 'legacy-heuristic', True)\n",
            "('add', 'add', True, 'legacy-heuristic', False)\n",
            "('add', 'add', True, 'legacy-heuristic', 0)\n",
            "('add', 'add', False, 'estimated', True)\n",
            "('add', 'add', False, 'estimated', False)\n",
            "('add', 'add', False, 'estimated', 0)\n",
            "('add', 'add', False, 'heuristic', True)\n",
            "('add', 'add', False, 'heuristic', False)\n",
            "('add', 'add', False, 'heuristic', 0)\n",
            "('add', 'add', False, 'legacy-heuristic', True)\n",
            "('add', 'add', False, 'legacy-heuristic', False)\n",
            "('add', 'add', False, 'legacy-heuristic', 0)\n",
            "('add', 'mul', True, 'estimated', True)\n",
            "('add', 'mul', True, 'estimated', False)\n",
            "('add', 'mul', True, 'estimated', 0)\n",
            "('add', 'mul', True, 'heuristic', True)\n",
            "('add', 'mul', True, 'heuristic', False)\n",
            "('add', 'mul', True, 'heuristic', 0)\n",
            "('add', 'mul', True, 'legacy-heuristic', True)\n",
            "('add', 'mul', True, 'legacy-heuristic', False)\n",
            "('add', 'mul', True, 'legacy-heuristic', 0)\n",
            "('add', 'mul', False, 'estimated', True)\n",
            "('add', 'mul', False, 'estimated', False)\n",
            "('add', 'mul', False, 'estimated', 0)\n",
            "('add', 'mul', False, 'heuristic', True)\n",
            "('add', 'mul', False, 'heuristic', False)\n",
            "('add', 'mul', False, 'heuristic', 0)\n",
            "('add', 'mul', False, 'legacy-heuristic', True)\n",
            "('add', 'mul', False, 'legacy-heuristic', False)\n",
            "('add', 'mul', False, 'legacy-heuristic', 0)\n",
            "('mul', 'add', True, 'estimated', True)\n",
            "('mul', 'add', True, 'estimated', False)\n",
            "('mul', 'add', True, 'estimated', 0)\n",
            "('mul', 'add', True, 'heuristic', True)\n",
            "('mul', 'add', True, 'heuristic', False)\n",
            "('mul', 'add', True, 'heuristic', 0)\n",
            "('mul', 'add', True, 'legacy-heuristic', True)\n",
            "('mul', 'add', True, 'legacy-heuristic', False)\n",
            "('mul', 'add', True, 'legacy-heuristic', 0)\n",
            "('mul', 'add', False, 'estimated', True)\n",
            "('mul', 'add', False, 'estimated', False)\n",
            "('mul', 'add', False, 'estimated', 0)\n",
            "('mul', 'add', False, 'heuristic', True)\n",
            "('mul', 'add', False, 'heuristic', False)\n",
            "('mul', 'add', False, 'heuristic', 0)\n",
            "('mul', 'add', False, 'legacy-heuristic', True)\n",
            "('mul', 'add', False, 'legacy-heuristic', False)\n",
            "('mul', 'add', False, 'legacy-heuristic', 0)\n",
            "('mul', 'mul', True, 'estimated', True)\n",
            "('mul', 'mul', True, 'estimated', False)\n",
            "('mul', 'mul', True, 'estimated', 0)\n",
            "('mul', 'mul', True, 'heuristic', True)\n",
            "('mul', 'mul', True, 'heuristic', False)\n",
            "('mul', 'mul', True, 'heuristic', 0)\n",
            "('mul', 'mul', True, 'legacy-heuristic', True)\n",
            "('mul', 'mul', True, 'legacy-heuristic', False)\n",
            "('mul', 'mul', True, 'legacy-heuristic', 0)\n",
            "('mul', 'mul', False, 'estimated', True)\n",
            "('mul', 'mul', False, 'estimated', False)\n",
            "('mul', 'mul', False, 'estimated', 0)\n",
            "('mul', 'mul', False, 'heuristic', True)\n",
            "('mul', 'mul', False, 'heuristic', False)\n",
            "('mul', 'mul', False, 'heuristic', 0)\n",
            "('mul', 'mul', False, 'legacy-heuristic', True)\n",
            "('mul', 'mul', False, 'legacy-heuristic', False)\n",
            "('mul', 'mul', False, 'legacy-heuristic', 0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAeE7vmJzzpR",
        "outputId": "2af558b4-fb56-4883-b837-68010f2f3a51"
      },
      "source": [
        "best_score = float('inf')\n",
        "best_options = None\n",
        "for x in itertools.product(*tuple_of_option_lists):\n",
        "  score = walkforward(*x)\n",
        "\n",
        "  if score < best_score:\n",
        "    print(\"Best score so far:\", score)\n",
        "    best_score = score\n",
        "    best_options = x"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best score so far: 380.65232061527036\n",
            "Best score so far: 241.5619978704101\n",
            "Best score so far: 241.24315400926346\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/holtwinters/model.py:80: RuntimeWarning: overflow encountered in matmul\n",
            "  return err.T @ err\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/holtwinters/model.py:80: RuntimeWarning: overflow encountered in matmul\n",
            "  return err.T @ err\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/holtwinters/model.py:80: RuntimeWarning: overflow encountered in matmul\n",
            "  return err.T @ err\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/holtwinters/model.py:80: RuntimeWarning: overflow encountered in matmul\n",
            "  return err.T @ err\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/holtwinters/model.py:80: RuntimeWarning: overflow encountered in matmul\n",
            "  return err.T @ err\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/holtwinters/model.py:80: RuntimeWarning: overflow encountered in matmul\n",
            "  return err.T @ err\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/holtwinters/model.py:80: RuntimeWarning: overflow encountered in matmul\n",
            "  return err.T @ err\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best score so far: 241.02106331277878\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/holtwinters/model.py:80: RuntimeWarning: overflow encountered in matmul\n",
            "  return err.T @ err\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best score so far: 212.89909403206025\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/holtwinters/model.py:80: RuntimeWarning: overflow encountered in matmul\n",
            "  return err.T @ err\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/holtwinters/model.py:80: RuntimeWarning: overflow encountered in matmul\n",
            "  return err.T @ err\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/holtwinters/model.py:80: RuntimeWarning: overflow encountered in matmul\n",
            "  return err.T @ err\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best score so far: 209.89845401368112\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/holtwinters/model.py:80: RuntimeWarning: overflow encountered in matmul\n",
            "  return err.T @ err\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/holtwinters/model.py:80: RuntimeWarning: overflow encountered in matmul\n",
            "  return err.T @ err\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUiHvMck0q-5",
        "outputId": "3c5a3ac5-4d3e-4e36-db20-1553d0f897fe"
      },
      "source": [
        "print(\"best score:\", best_score)\n",
        "\n",
        "trend_type, seasonal_type, damped_trend, init_method, use_boxcox = best_options\n",
        "print(\"trend_type\", trend_type)\n",
        "print(\"seasonal_type\", seasonal_type)\n",
        "print(\"damped_trend\", damped_trend)\n",
        "print(\"init_method\", init_method)\n",
        "print(\"use_boxcox\", use_boxcox)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best score: 209.89845401368112\n",
            "trend_type mul\n",
            "seasonal_type mul\n",
            "damped_trend False\n",
            "init_method estimated\n",
            "use_boxcox False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In7cxrrO1Ka3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}